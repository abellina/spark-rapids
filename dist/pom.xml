<?xml version="1.0" encoding="UTF-8"?>
<!--
  Copyright (c) 2020-2021, NVIDIA CORPORATION.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <parent>
    <groupId>com.nvidia</groupId>
    <artifactId>rapids-4-spark-parent</artifactId>
    <version>21.08.0-SNAPSHOT</version>
  </parent>
  <artifactId>rapids-4-spark_2.12</artifactId>
  <name>RAPIDS Accelerator for Apache Spark Distribution</name>
  <description>Creates the distribution package of the RAPIDS plugin for Apache Spark</description>

  <dependencies>
    <dependency>
       <groupId>com.nvidia</groupId>
       <artifactId>rapids-4-spark-sql_${scala.binary.version}</artifactId>
       <version>${project.version}</version>
    </dependency>
    <dependency>
       <groupId>com.nvidia</groupId>
       <artifactId>rapids-4-spark-shuffle_${scala.binary.version}</artifactId>
       <version>${project.version}</version>
    </dependency>
    <dependency>
       <groupId>com.nvidia</groupId>
       <artifactId>rapids-4-spark-shims-aggregator_${scala.binary.version}</artifactId>
       <version>${project.version}</version>
    </dependency>
    <dependency>
       <groupId>com.nvidia</groupId>
       <artifactId>rapids-4-spark-udf_${scala.binary.version}</artifactId>
       <version>${project.version}</version>
    </dependency>
    <dependency>
       <!-- required for conf generation script -->
       <groupId>org.apache.spark</groupId>
       <artifactId>spark-sql_${scala.binary.version}</artifactId>
       <scope>provided</scope>
    </dependency>
    <dependency>
      <!-- required for conf generation script -->
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-hive_${scala.binary.version}</artifactId>
      <scope>provided</scope>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <configuration>
          <relocations>
            <!-- Shade ORC and Hive and their dependencies -->
            <relocation>
              <pattern>org.apache.orc.</pattern>
              <shadedPattern>${rapids.shade.package}.orc.</shadedPattern>
            </relocation>
            <relocation>
              <pattern>org.apache.hadoop.hive.</pattern>
              <shadedPattern>${rapids.shade.package}.hadoop.hive.</shadedPattern>
              <excludes>
                <exclude>org.apache.hadoop.hive.conf.HiveConf</exclude>
                <exclude>org.apache.hadoop.hive.ql.exec.UDF</exclude>
                <exclude>org.apache.hadoop.hive.ql.udf.generic.GenericUDF</exclude>
              </excludes>
            </relocation>
            <relocation>
              <pattern>org.apache.hive.</pattern>
              <shadedPattern>${rapids.shade.package}.hive.</shadedPattern>
            </relocation>
            <relocation>
              <pattern>io.airlift.compress.</pattern>
              <shadedPattern>${rapids.shade.package}.io.airlift.compress.</shadedPattern>
            </relocation>
            <relocation>
              <pattern>org.apache.commons.codec.</pattern>
              <shadedPattern>${rapids.shade.package}.org.apache.commons.codec.</shadedPattern>
            </relocation>
            <relocation>
              <pattern>org.apache.commons.lang.</pattern>
              <shadedPattern>${rapids.shade.package}.org.apache.commons.lang.</shadedPattern>
            </relocation>

            <!-- Shade Guava, Flatbuffers, and Protobuf -->
            <relocation>
              <pattern>com.google</pattern>
              <shadedPattern>${rapids.shade.package}.com.google</shadedPattern>
            </relocation>
          </relocations>
        </configuration>
        <!-- number of shims can be reduced to the number of compatibility domain
         Use the most recent version from each compatibilty domain. Typically we expect
         that patch releases are backwards compatible. So we take the shim representing the
         most recent version in the backwards compatibility domain to take care of the entire
         domain

         spark3.0.1 through spark 3.0.3, potentially 3.0.4 if the current breakage is eliminated
         spark 3.1.x , as long as patch version don't break us
         spark 3.2.x,  as long as patch version don't break us
         -->
        <executions>
          <execution>
            <id>shim-common-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>common</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
              <createDependencyReducedPom>true</createDependencyReducedPom>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
              </transformers>
              <artifactSet>
                <includes>
                  <include>*:rapids-4-spark-shims-spark3*_${scala.binary.version}:*</include>
                  <include>com.google.flatbuffers:flatbuffers-java</include>
                  <include>com.google.guava:guava</include>
                  <include>com.google.protobuf:protobuf-java</include>
                  <include>commons-codec:commons-codec</include>
                  <include>commons-lang:commons-lang</include>
                  <include>io.airlift:aircompressor</include>
                  <include>org.apache.hive:hive-storage-api</include>
                  <include>org.apache.orc:orc-core</include>
                  <include>org.apache.orc:orc-mapreduce</include>
                  <include>org.apache.orc:orc-shims</include>
                </includes>
              </artifactSet>
            </configuration>
          </execution>

          <execution>
            <id>shim301-fat-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>spark301</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
                <createDependencyReducedPom>true</createDependencyReducedPom>
                <transformers>
                    <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                </transformers>
                <artifactSet>
                    <includes>
                      <include>*:rapids-4-spark-shims-spark301_${scala.binary.version}:*</include>
                      <include>com.google.flatbuffers:flatbuffers-java</include>
                      <include>com.google.guava:guava</include>
                      <include>com.google.protobuf:protobuf-java</include>
                      <include>commons-codec:commons-codec</include>
                      <include>commons-lang:commons-lang</include>
                      <include>io.airlift:aircompressor</include>
                      <include>org.apache.hive:hive-storage-api</include>
                      <include>org.apache.orc:orc-core</include>
                      <include>org.apache.orc:orc-mapreduce</include>
                      <include>org.apache.orc:orc-shims</include>
                    </includes>
                </artifactSet>
            </configuration>
          </execution>
          <execution>
            <id>shim302-fat-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>spark302</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
                <createDependencyReducedPom>true</createDependencyReducedPom>
                <transformers>
                    <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                </transformers>
                <artifactSet>
                    <includes>
                      <include>*:rapids-4-spark-shims-spark302_${scala.binary.version}:*</include>
                      <include>com.google.flatbuffers:flatbuffers-java</include>
                      <include>com.google.guava:guava</include>
                      <include>com.google.protobuf:protobuf-java</include>
                      <include>commons-codec:commons-codec</include>
                      <include>commons-lang:commons-lang</include>
                      <include>io.airlift:aircompressor</include>
                      <include>org.apache.hive:hive-storage-api</include>
                      <include>org.apache.orc:orc-core</include>
                      <include>org.apache.orc:orc-mapreduce</include>
                      <include>org.apache.orc:orc-shims</include>
                    </includes>
                </artifactSet>
            </configuration>
          </execution>
          <execution>
            <id>shim303-fat-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>spark303</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
                <createDependencyReducedPom>true</createDependencyReducedPom>
                <transformers>
                    <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                </transformers>
                <artifactSet>
                    <includes>
                      <include>*:rapids-4-spark-shims-spark303_${scala.binary.version}:*</include>
                      <include>com.google.flatbuffers:flatbuffers-java</include>
                      <include>com.google.guava:guava</include>
                      <include>com.google.protobuf:protobuf-java</include>
                      <include>commons-codec:commons-codec</include>
                      <include>commons-lang:commons-lang</include>
                      <include>io.airlift:aircompressor</include>
                      <include>org.apache.hive:hive-storage-api</include>
                      <include>org.apache.orc:orc-core</include>
                      <include>org.apache.orc:orc-mapreduce</include>
                      <include>org.apache.orc:orc-shims</include>
                    </includes>
                </artifactSet>
            </configuration>
          </execution>
          <execution>
            <id>shim311-fat-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>spark311</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
                <createDependencyReducedPom>true</createDependencyReducedPom>
                <transformers>
                    <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                </transformers>
                <artifactSet>
                    <includes>
                      <include>*:rapids-4-spark-shims-spark311_${scala.binary.version}:*</include>
                      <include>com.google.flatbuffers:flatbuffers-java</include>
                      <include>com.google.guava:guava</include>
                      <include>com.google.protobuf:protobuf-java</include>
                      <include>commons-codec:commons-codec</include>
                      <include>commons-lang:commons-lang</include>
                      <include>io.airlift:aircompressor</include>
                      <include>org.apache.hive:hive-storage-api</include>
                      <include>org.apache.orc:orc-core</include>
                      <include>org.apache.orc:orc-mapreduce</include>
                      <include>org.apache.orc:orc-shims</include>
                    </includes>
                </artifactSet>
            </configuration>
          </execution>
          <execution>
            <id>shim312-fat-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>spark312</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
                <createDependencyReducedPom>true</createDependencyReducedPom>
                <transformers>
                    <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                </transformers>
                <artifactSet>
                    <includes>
                      <include>*:rapids-4-spark-shims-spark312_${scala.binary.version}:*</include>
                      <include>com.google.flatbuffers:flatbuffers-java</include>
                      <include>com.google.guava:guava</include>
                      <include>com.google.protobuf:protobuf-java</include>
                      <include>commons-codec:commons-codec</include>
                      <include>commons-lang:commons-lang</include>
                      <include>io.airlift:aircompressor</include>
                      <include>org.apache.hive:hive-storage-api</include>
                      <include>org.apache.orc:orc-core</include>
                      <include>org.apache.orc:orc-mapreduce</include>
                      <include>org.apache.orc:orc-shims</include>
                    </includes>
                </artifactSet>
            </configuration>
          </execution>
          <execution>
            <id>shim320-fat-jar</id>
            <goals><goal>shade</goal></goals>
            <configuration>
              <shadedClassifierName>spark320</shadedClassifierName>
              <shadedArtifactAttached>true</shadedArtifactAttached>
              <createDependencyReducedPom>true</createDependencyReducedPom>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
              </transformers>
              <artifactSet>
                <includes>
                  <include>*:rapids-4-spark-shims-spark320_${scala.binary.version}:*</include>
                  <include>com.google.flatbuffers:flatbuffers-java</include>
                  <include>com.google.guava:guava</include>
                  <include>com.google.protobuf:protobuf-java</include>
                  <include>commons-codec:commons-codec</include>
                  <include>commons-lang:commons-lang</include>
                  <include>io.airlift:aircompressor</include>
                  <include>org.apache.hive:hive-storage-api</include>
                  <include>org.apache.orc:orc-core</include>
                  <include>org.apache.orc:orc-mapreduce</include>
                  <include>org.apache.orc:orc-shims</include>
                </includes>
              </artifactSet>
            </configuration>
          </execution>
        </executions>
      </plugin>
      <!-- iterate individual fat jars to create a single fat jar with the the dependencies prefixed -->
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-antrun-plugin</artifactId>
        <executions>
          <execution>
            <phase>prepare-package</phase>
            <goals><goal>run</goal></goals>
            <id>delete-shim-clases</id>
            <configuration>
              <target>
                <delete
                        dir="${project.build.directory}/parallel-world"
                        includeemptydirs="true"
                />

                <delete>
                  <fileset
                          dir="${project.build.directory}"
                          includes="*.jar"
                  />
                </delete>
              </target>
            </configuration>
          </execution>
          <execution>
            <phase>package</phase>
            <goals><goal>run</goal></goals>
            <id>create-parallel-world</id>
            <configuration>
              <target>
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-common.jar"
                        dest="${project.build.directory}/parallel-world"
                >
                  <patternset id="sharedWorld">
                    <includesfile name="${project.basedir}/unshimmed-classes.txt"/>
                    <includesfile name="${project.basedir}/unshimmed-extras.txt"/>
                  </patternset>
                </unzip>

<!--                unzip task seems to be broken for $$ files, so using exec with jar -->
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-common.jar"
                        dest="${project.build.directory}/parallel-world/spark3xx-common"
                >
                  <!--
                  TODO generate automatically based on the number of shims in the build
                  this example works for 3 shims. If we find 3 duplicates of a class then it can
                  be shared

                  find shims -name \*.class -exec md5sum {} + |
                    sort -k 1 |
                    uniq -w32 -c | tr -s ' ' | grep '^ 3 ' | cut -d'/' -f 5- | sort > dist/unshimmed-classes.txt
                  -->
                  <patternset id="sharedWorld">
                    <excludesfile name="${project.basedir}/shimmed-classes.txt"/>
                    <excludesfile name="${project.basedir}/unshimmed-classes.txt"/>
                  </patternset>
                </unzip>

                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-spark301.jar"
                        dest="${project.build.directory}/parallel-world/spark301"
                >
                  <!-- to keep in sync with sharedWorld: inverse it to exclude -->
                  <patternset id="shimPattern">
                    <includesfile name="${project.basedir}/shimmed-classes.txt"/>
                  </patternset>
                </unzip>
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-spark302.jar"
                        dest="${project.build.directory}/parallel-world/spark302"
                >
                  <patternset refid="shimPattern"/>
                </unzip>
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-spark303.jar"
                        dest="${project.build.directory}/parallel-world/spark303"
                >
                  <patternset refid="shimPattern"/>
                </unzip>
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-spark311.jar"
                        dest="${project.build.directory}/parallel-world/spark311"
                >
                  <patternset refid="shimPattern"/>
                </unzip>
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-spark312.jar"
                        dest="${project.build.directory}/parallel-world/spark312"
                >
                  <patternset refid="shimPattern"/>
                </unzip>
                <unzip
                        src="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}-spark320.jar"
                        dest="${project.build.directory}/parallel-world/spark320"
                >
                  <patternset refid="shimPattern"/>
                </unzip>
                <jar
                        destfile="${project.build.directory}/rapids-4-spark_${scala.binary.version}-${project.version}.jar"
                        basedir="${project.build.directory}/parallel-world"
                >
                </jar>
              </target>
            </configuration>
          </execution>
        </executions>
      </plugin>

      <plugin>
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
        <executions>
          <execution>
            <id>update_config</id>
            <phase>none</phase>
            <goals>
              <goal>run</goal>
            </goals>
            <configuration>
              <launchers>
                <launcher>
                  <id>update_rapids_config</id>
                  <mainClass>com.nvidia.spark.rapids.RapidsConf</mainClass>
                  <args>
                    <arg>${project.basedir}/../docs/configs.md</arg>
                  </args>
                </launcher>
              </launchers>
            </configuration>
          </execution>
          <execution>
            <id>update_supported</id>
            <phase>none</phase>
            <goals>
              <goal>run</goal>
            </goals>
            <configuration>
              <launchers>
                <launcher>
                  <id>update_rapids_support</id>
                  <mainClass>com.nvidia.spark.rapids.SupportedOpsDocs</mainClass>
                  <args>
                    <arg>${project.basedir}/../docs/supported_ops.md</arg>
                  </args>
                </launcher>
              </launchers>
            </configuration>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.apache.rat</groupId>
        <artifactId>apache-rat-plugin</artifactId>
      </plugin>
    </plugins>
  </build>

  <profiles>
    <profile>
      <id>pre-merge</id>
      <build>
        <plugins>
          <plugin>
            <groupId>org.codehaus.mojo</groupId>
            <artifactId>exec-maven-plugin</artifactId>
            <executions>
              <execution>
                <id>if_modified_files</id>
                <phase>verify</phase>
                <goals>
                  <goal>exec</goal>
                </goals>
                <configuration>
                  <executable>bash</executable>
                  <commandlineArgs>-c 'export MODIFIED=$(git status --porcelain | grep "^ M"); [[ -z $MODIFIED ]] &amp;&amp; exit 0 || { echo -e "found modified files during mvn verify:\n$MODIFIED"; exit 1;}'</commandlineArgs>
                </configuration>
              </execution>
            </executions>
          </plugin>
        </plugins>
      </build>
      <activation>
        <activeByDefault>false</activeByDefault>
      </activation>
    </profile>
  </profiles>

</project>
